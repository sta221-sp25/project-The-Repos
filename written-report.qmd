---
title: "Written Report on Factors that Help Diagnose Autism"
author: "The Repos - Jeffrey Bohrer, Alexandra Green, Anna Zhang, Kevin Lee"
date: "March 20, 2025"
format: pdf
editor: visual
---

```{r, echo=FALSE, message = FALSE}
library(tidyverse)
library(tidymodels)
library(patchwork)
library(knitr)
library(tibble)
library(kableExtra)
library(glmnet)
library(pROC)
library(car)
library(corrplot)
library(ggcorrplot)
library(Stat2Data)  
library(broom)#empirical logit plots

autism_ds <- read_csv("data/autism_ds.csv") %>%
  mutate(ethnicity = ifelse(ethnicity == "others", "Others", ethnicity))
```

**I. Introduction**

Autism Spectrum Disorder (ASD) remains a highly prevalent condition despite modern strides made in medical technology. It is reported that nearly 2.2% of adults are affected by ASD, and growing awareness has led to an uptick in diagnoses, particularly in adults who went undiagnosed early in life (Hirota 2023). However, ASD screening tests for all age groups currently contain significant inaccuracies. For example, the most widely used toddler screening test, CHAT-R/FAs, was recently found to produce false negatives in 25% of cases. In contrast, the most commonly used adult autism screening test – the Autism-Spectrum Quotient (AQ) – was found to have limited predictive value in certain populations (Aishworiya 2023; Curnow 2023). Therefore, it has become critical to identify stronger predictors or explore underlying relationships to have more accurate tests and models to predict ASD in adults.

In this study, we will focus on identifying the features that most greatly affect the probability of being encouraged to pursue a diagnosis within this particular questionaire, as created by Prof. Fadi Thabtau of the Manukau Institute of Technology. The data was sourced from users of his app, ASDTests, which screens its users for potential indicators of autism using a ten-question survey. Admittedly then, we are working with the population of individuals or those with relationship to individuals seeking screening for ASD, which could prevent generalization to greater populations. The data set being used will contain nine demographic characteristics – ranging from ethnicity to presence of neonatal jaundice – along with the answers of each individual to the ten behavioral questions of this survey.

Because ASD is difficult to identify and can significantly impair an individual's quality of life, understanding the relationship between demographics, certain behaviors, and their association with autism could encourage individuals to seek diagnosis and gain self-understanding. These adults who receive a positive diagnosis can then access the necessary resources for support. Accordingly, our research question is: what aspects of this questionnaire are most closely associated with being encouraged to pursue an autism diagnosis?

For these purposes, both univariate and bivariate data analyses will be pursued as a means of assessing relevant avenues for further investigation and model fitting. We relabeled the features representing questions in the data set with their actual wording for interpretability, in addition to representing "Yes" as a 1 and "No" as a 0 for their values. The exploratory data analysis of the demographic data and questions can be found in the following pages.

**i. Univariate EDA**

```{r, include =FALSE}
as.data.frame(as.matrix(summary(autism_ds$result)))%>%
  kable(digits = 3)
prop_high_scores <- nrow(autism_ds[autism_ds$'Class/ASD' == 'YES', ])/nrow(autism_ds)
cat("Proportion of scores indicative:", round(prop_high_scores, 3), "\n")
```

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of total scores across dataset", fig.height=1.5, fig.width=5.5}
autism_ds |>
  ggplot(aes(x = result)) +
  geom_bar(fill = "skyblue") +
  scale_x_continuous(breaks = seq(0, 10, 1), 
                     labels = as.character(seq(0, 10, 1))) +
  labs(x = "Score",
       y = "Count",
       title = "Score Distribution") + 
  theme_minimal()
```

The variable we are most interested in – the final score of users – ranges from 0 to 10, which makes sense as 10 behavioral questions can be answered either 'Yes' or 'No'. The mean score is 5.077, and the median is 5, both of which are relatively high considering that scores above 6 warrant further diagnostic evaluation. However, because suspecting a diagnosis is a reason for taking the test to begin with, these statistics are reasonable reflections of the test-taking population. We also observe that roughly 30% of test takers are encouraged to seek a diagnosis due to a score higher than 6. We also observe the IQR to be 4 points, as most test takers have a score between 3 and 7 points inclusive. In the context of the data, such a spread is reasonable, and no outliers exist which is understandable given the limited range of scores.

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of ethnicities across dataset", fig.height=2, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  ggplot(aes(x = fct_infreq(ethnicity))) +
  geom_bar(fill = "skyblue") +
  labs(x = "Ethnicity",
       y = "Count",
       title = "Distribution of Ethnicity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We observe here that the most common ethnicity was White-Europeans, with over 200 observations in our data set. Secondly and thirdly, we observe the Asian and Middle Eastern populations to be above 100 and slightly below 100 observations, respectively. All other ethnicities have fewer than 50 observations in our data set, suggesting it may be more difficult to conclude about these populations. We can now check whether the proportion of individuals encouraged to seek a diagnosis varies by ethnicity:

```{r, echo=FALSE, message = FALSE, fig.cap="Proportion of indicative score across ethnicities", fig.height=2, fig.width=5.5}
autism_ds %>%
  group_by(ethnicity) %>%
  summarize(yes_count = sum(`Class/ASD` == "YES"),
            total_count = n(),
            proportion_yes = yes_count / total_count) %>%
  ggplot(aes(x = fct_reorder(ethnicity, proportion_yes, .desc=TRUE), y = proportion_yes)) +
  geom_col(fill = "skyblue") +
  labs(x = "Ethnicity",
       y = "Proportion
       High Scores",
       title = "Proportion of Indicative Test Scores by Ethnicity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

As we can see here, the population with the highest proportion of test takers receiving a high test score was the Latino population, with close to half achieving a score higher than a 6. Since this is a comparably uncommon population in our data set, it does raise questions of whether it is indicative of the greater Latino population or merely due to the smaller sample size in our data set. Additionally, the White-European, Black, and Hispanic populations also demonstrate a greater proportion of high test scores. The variation in these proportions according to ethnicity also warrants further exploration into how the distribution of test scores differs by ethnicity. Specifically, the questions remain of whether this means the rates of under- or over-diagnosis vary for different ethnic groups, and if so, what alterations in this questionnaire would be necessary to ameliorate these errors.

```{r, include = FALSE}
summary(autism_ds$age)
```

```{r, echo=FALSE, message = FALSE, warning=FALSE, fig.cap="Age distribution across dataset", fig.height=1.5, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  ggplot(aes(x = age)) +
  geom_bar(fill = "skyblue") +
  labs(x = "Age",
       y = "Count",
       title = "Distribution of Age") +
  xlim(10, 75) + 
  theme_minimal()
```

Generally, we observe the distribution of ages to possess a strong right-skewness, with a mean age of 30.22 and a median age of 27. There is a clear peak in the age distribution roughly around the early to mid-20s. The ages range from a minimum of 17 to a maximum of 383 – a false observation that should be filtered from the data. The IQR is 13 years, which is a fairly small spread given the range of ages, as we observe that the majority of test-takers are under 30 years old.

```{r, echo=FALSE, message = FALSE, fig.cap='Distribution of Y/N responses for Q1-10. Details of what each question represents can be found in the data dictionary and in appendix.', fig.height=1.5, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  mutate(
    small_sounds = if_else(small_sounds == 1, "Yes", "No"),
    difficult_to_understand_char = if_else(difficult_to_understand_char == 1, "Yes", "No"),
    ease_to_read_between_lines = if_else(ease_to_read_between_lines == 1, "Yes", "No"),
    focus_on_whole_picture = if_else(focus_on_whole_picture == 1, "Yes", "No"),
    i_can_tell_if_someone_bored = if_else(i_can_tell_if_someone_bored == 1, "Yes", "No"),
    i_can_multi_task = if_else(i_can_multi_task == 1, "Yes", "No"),
    i_can_tell_feelings_from_faces = if_else(i_can_tell_feelings_from_faces == 1, "Yes", "No"),
    i_can_go_back_to_work_when_interrupted = if_else(i_can_go_back_to_work_when_interrupted == 1, "Yes", "No"),
    i_like_to_collect_info_on_categories = if_else(i_like_to_collect_info_on_categories == 1, "Yes", "No"),
    i_find_it_hard_to_figure_out_others_intentions = if_else(i_find_it_hard_to_figure_out_others_intentions == 1, "Yes", "No")
  ) |>
  rename(
    `Q1` = small_sounds,
    `Q2` = difficult_to_understand_char,
    `Q3` = ease_to_read_between_lines,
    `Q4` = focus_on_whole_picture,
    `Q5` = i_can_tell_if_someone_bored,
    `Q6` = i_can_multi_task,
    `Q7` = i_can_tell_feelings_from_faces,
    `Q8` = i_can_go_back_to_work_when_interrupted,
    `Q9` = i_like_to_collect_info_on_categories,
    `Q10` = i_find_it_hard_to_figure_out_others_intentions
  ) |>
  select("Q1":"Q10") |>
  pivot_longer(everything(), names_to = "question", values_to = "response") |>
  mutate(
    question = factor(question, levels = paste0("Q", 1:10))  
  ) |>
  ggplot(aes(x = question, fill = response)) +
  geom_bar(position = "fill") +
  labs(
    x = "Question",
    y = "Proportion",
    title = "Distribution of Yes/No Responses to Screening Questions",
    fill = "Response"
  ) +
  scale_fill_brewer(palette = "Blues") +
  theme_minimal()
```

The two questions with the highest proportion of "Yes" responses were Q1 and Q8, suggesting that these behaviors are common among respondents. On the other hand, Q6 and Q9 had noticeably lower "Yes" responses, potentially indicating difficulties in such areas. Most questions, however, had roughly even proportions between "Yes" and "No" responses.

**ii. Bivariate EDA**

```{r, echo=FALSE, message = FALSE, warning = FALSE, fig.cap="Score distribution across ethnicities", fig.height=2.25, fig.width=5.5}
### Result score distributions by ethnicity
ggplot(autism_ds, 
       aes(y = result,
           x = ethnicity,
           fill = ethnicity)) +
  geom_boxplot() +
  labs(
    title = "Scores Distributions Across Ethnicity",
    y = "Score",
    fill = "Ethnicity",
    x = ""
  )  +
  scale_fill_brewer(palette = "Blues", guide = "none")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Here we present several graphs displaying bivariate relationships. With our first set of box plots, we find further evidence for our previous suspicion that test score distributions differ by ethnicity. Although most ethnicities have a median within the range of roughly 3 to 6, some ethnicities, like the White-European, Black, and Hispanic populations, demonstrate a greater spread through their larger IQRs, while the Turkish, Middle Eastern, and Asian populations are much more concentrated around their medians. However, most ethnicities appear to have values almost entirely across the range of 0 to 10 in their test scores.

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of scores by respondent type", fig.height=2, fig.width=5.5}
ggplot(autism_ds, 
       aes(y = result,
           x = relation,
           fill = relation)) +
  geom_violin(alpha = 0.5) +
  labs(
    title = "Score Distribution by Respondent Type",
    y = "Score",
    x = "Relation"
  ) +
  scale_fill_brewer(palette = "Blues", guide = "none") +
  theme_minimal()

```

Interestingly, we can also observe how the relationship between the test taker and the subject of the questions may lead to different distributions of test scores. In the case when it is filled out by a relative or health care professional for example, the observed test score is 2 or greater, while in the case of the test taker being the subject or the parent of the subject, some still received a score of 0. This could reflect how personal biases or relationships affect truthfulness during the test.

This initial exploration leads us to investigate particularly how our demographic data may impact the odds of being encouraged to seek a formal diagnosis, as observed by a high score on this screening test. Though we cannot definitively answer whether it is due to social or cultural perceptions of autism within and surrunding these subgroups or true differences in rates of its presence, it is worth identifying whether over- or under-diagnosis for certain populations is possible.

**II. Methodology**

**i. Choosing Predictors**

Firstly, a drop-in-deviance test between a logistic null model without predictor variables and only an intercept, and a logistic model with a single predictor was systematically conducted across ethnicity, gender, presence of neonatal jaundice, and relationship to the subject as a means of assessing which predictors provide a statistically significant improvement in model fit against this null condition. This was done to gain information on the relationship between demographic data and test scores. The hypothesis for this test can be observed below, where $\beta_1$ represents the coefficient for the associated predictor variable: $$H_0: \beta_{predictor} = 0$$ $$H_a: \beta_{predictor} \neq 0$$ The formulas for the models compared are the following: $$Null:log(\frac{\hat\pi}{1-\hat\pi})=\beta_0$$ $$Alternative:log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_{predictor}x_{predictor}$$ The following table summarizes the results

```{r, include = FALSE}
### Ethnicity DD
autism_ds <- autism_ds %>%
  mutate(highProb = if_else(`Class/ASD` == "YES", 1, 0))

reduced_model <- glm(highProb ~ 1, 
              data = autism_ds, family = "binomial")
ethnicity_model <- glm(highProb ~ ethnicity, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_eth <- -2 * glance(ethnicity_model)$logLik), "\n")
cat("G-stat:", (G_eth <- deviance_reduced - deviance_eth), "\n")
cat("p-value:", pchisq(G_eth, df = 9, lower.tail = FALSE), "\n")

tidy(ethnicity_model) |>
  kable(digits = 3)
```

```{r, include =FALSE}
### Relation DD

relation_model <- glm(highProb ~ relation, 
              data = autism_ds, family = "binomial")

cat("D-reduced:",(deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-fulll:",(deviance_rel <- -2 * glance(relation_model)$logLik), "\n")
cat("G-stat:",(G_rel<- deviance_reduced - deviance_rel), "\n")
cat("p-value:",pchisq(G_rel, df = 4, lower.tail = FALSE), "\n")

tidy(relation_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
## Age
age_model <- glm(highProb ~ age, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_age <- -2 * glance(age_model)$logLik), "\n")
cat("G-stat:", (G_age <- deviance_reduced - deviance_age), "\n")
cat("p-value:", pchisq(G_age, df = 1, lower.tail = FALSE), "\n")

tidy(age_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
### Gender
gender_model <- glm(highProb ~ gender, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_gender <- -2 * glance(gender_model)$logLik), "\n")
cat("G-stat:", (G_gender <- deviance_reduced - deviance_gender), "\n")
cat("p-value:", pchisq(G_gender, df = 1, lower.tail = FALSE), "\n")

tidy(gender_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
### Jaundice
jaundice_model <- glm(highProb ~ jundice, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_j <- -2 * glance(jaundice_model)$logLik), "\n")
cat("G-stat:", (G_j <- deviance_reduced - deviance_j), "\n")
cat("p-value:", pchisq(G_j, df = 1, lower.tail = FALSE), "\n")

tidy(jaundice_model) |>
  kable(digits = 3)
```

```{r, message=FALSE, echo =FALSE, tab.cap="Non-obvious predictors drop-in-deviance test results" }
header <- c("Deviance", "G statistic (respect to null)", "p-value")
Null <- c(round(deviance_reduced, 3), "NA", "NA")

Ethnicity <- c(round(deviance_eth, 3), round(G_eth,3), round(pchisq(G_eth, df = 9, lower.tail = FALSE),5))
Relation <- c(round(deviance_rel,3), round(G_rel,3), round(pchisq(G_rel, df = 4, lower.tail = FALSE),3))
Age <- c(round(deviance_age,3), round(G_age,3), round(pchisq(G_age, df = 1, lower.tail = FALSE),3))
Gender <- c(round(deviance_gender,3), round(G_gender,3), round(pchisq(G_gender, df = 1, lower.tail = FALSE),3))
Jaundice <- c(round(deviance_j,3), round(G_j,3),  round(pchisq(G_j, df = 1, lower.tail = FALSE),3))

non_obvious_pred <- rbind(Null, Ethnicity, Relation, Age, Gender, Jaundice)
colnames(non_obvious_pred) <- header

kable(non_obvious_pred)
```

The results show that the demographics that are statistically significant for the model fit are ethnicity, gender, and, quite surprisingly, neonatal jaundice, when compared to a null model, as the p-values are either significantly less than 0.05 (as in ethnicity) or slightly below it (gender and jaundice). We further investigate the correlation between answers to questions below, as a means of assessing if the test has any pitfalls regarding multicollinearity:

```{r, echo=FALSE, message = FALSE, fig.cap = "Correlation between AQ10 questions", fig.height=2.75, fig.width=10.5}
q1_to_10 <- autism_ds |>
  select(small_sounds, difficult_to_understand_char,
         ease_to_read_between_lines,
         focus_on_whole_picture,
         i_can_tell_if_someone_bored,
         i_can_multi_task,
         i_can_tell_feelings_from_faces,
         i_can_go_back_to_work_when_interrupted,
         i_like_to_collect_info_on_categories,
         i_find_it_hard_to_figure_out_others_intentions)

cor_matrix <- cor(q1_to_10, method = "pearson", use = "complete.obs")

short_names <- c(
  "Q1", "Q2", "Q3", "Q4", "Q5",
  "Q6", "Q7", "Q8", "Q9", "Q10"
)

colnames(cor_matrix) <- short_names
rownames(cor_matrix) <- short_names

corrplot(cor_matrix,
         method = "color",
         type = "upper",
         tl.col = "black",
         tl.cex = 1,
         addCoef.col = "black",
         number.cex = 0.7,
         diag = FALSE)
```

By computing a correlation heat map among the ten behavior questions to check multicollinearity, we note that surprisingly, only a few questions have stronger correlations with one another. This is rather unexpected since we would expect many behaviors to be grouped together and more correlated (e.g., social behaviors). However, the highest correlation is between questions 6 and 9, which are the questions about multitasking and liking to collect information, respectively – this is also a rather surprising pairing.

Considering this reality, principal component analysis was employed as a means of determining the question clusters that explain the highest variance to gain further understanding of the nature of the questions and their variety in the screening tets (Szczęsna, 2022; finnstats, 2021).

```{r, include=FALSE}
pca <- prcomp(autism_ds |>
     rename(
        `Q1` = small_sounds,
        `Q2` = difficult_to_understand_char,
        `Q3` = ease_to_read_between_lines,
        `Q4` = focus_on_whole_picture,
        `Q5` = i_can_tell_if_someone_bored,
        `Q6` = i_can_multi_task,
        `Q7` = i_can_tell_feelings_from_faces,
        `Q8` = i_can_go_back_to_work_when_interrupted,
        `Q9` = i_like_to_collect_info_on_categories,
        `Q10` = i_find_it_hard_to_figure_out_others_intentions
    ) |> select(Q1:Q10), center = TRUE, scale. = TRUE)
summary(pca)
# Loadings reshaped
loadings_df <- as.data.frame(pca$rotation[, 1:10]) |>
  rownames_to_column("question") |>
  pivot_longer(cols = -question, names_to = "PC", values_to = "loading")

# Keep question and PC order fixed
loadings_df$question <- factor(loadings_df$question, levels = paste0("Q", 1:10))
loadings_df$PC <- factor(loadings_df$PC, levels = paste0("PC", 1:10))
```

```{r, echo=FALSE, fig.cap = "Principal component analysis Q1-10 as a means of choosing questions that best explain the variance in the response", fig.height=6, fig.width=10.5}
# Plot
ggplot(loadings_df, aes(x = question, y = abs(loading), fill = PC)) +
  geom_col(position = "dodge") +
  coord_flip() +
  facet_wrap(~ PC, scales = "free_y") +
  labs(title = "PCA Loadings by Question", x = "Question", y = "Loading") +
  scale_fill_discrete(guide = "none") +
  theme_minimal()
```

We can observe that questions 3, 5, and 6 have high correlation to questions 4, 6, and 9 respectively as found in the correlation map. Beyond these three, the questions that also observe notable loading for principal components (i.e. the parameters that explain the most variance) are Q10, Q8, Q4, Q2, and Q1 (i.e finding it hard to figure out others intentions (Q10), ease of going back to work when interrupted (Q8), focus on whole picture (Q4), difficulty to understand characters in stories (Q2), and picking up on small sounds (Q1)). In general, it seems that some of these questions form categories that are highly correlated to explain the different subsets of behaviors in autism (e.g., social behaviors like reading expressions). \newpage

**ii. Fitting the Model**

As a means of identifying potential correlations between demographic data and the odds of a high test score, two models will be fitted and compared in terms of a drop-in-deviance test: (a) a null model fitted only to an intercept, and (b) a model that accounts for demographic data. Subsequently, the models fitted will be of the forms: $$Null:log(\frac{\hat\pi}{1-\hat\pi})=\beta_0$$ $$Alternative:log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_{ethnicity}X_{ethnicity}+\beta_{gender}X_{gender}+\beta_{jaundice}X_{jaundice}$$ And the hypotheses for the test will be the following: $$H_0: \beta_{ethnicity}=\beta_{gender}=\beta_{jaundice}=0$$ $$H_a: \beta_{ethnicity}, \beta_{gender}, \beta_{jaundice}\neq0 \space, \text{for at least one} \space \beta_j$$

This is to assess whether demographic predictors significantly improve model fit and our predictions of the odds of having a high score on the test, and accordingly, being encouraged to pursue a diagnosis. Additionally, AIC and BIC were included for further comparison.

```{r, include = FALSE}
autism_ds$ethnicity <- relevel(factor(autism_ds$ethnicity), ref = "White-European")
null_mod_score_fit <- glm(highProb ~ 1, 
                            data = autism_ds, family = "binomial")

alt_mod_score_fit <- glm(highProb ~ 
                            ethnicity + 
                            gender +
                            jundice,
                            data = autism_ds, family = "binomial")

dev_test <- anova(null_mod_score_fit, alt_mod_score_fit, test = "Chisq")

aic_null <- AIC(null_mod_score_fit)
bic_null <- BIC(null_mod_score_fit)
aic_alt <- AIC(alt_mod_score_fit)
bic_alt <- BIC(alt_mod_score_fit)

model_comparison <- tibble(
  Model = c("Null Model", "Alternative Model"),
  Residual_Deviance = c(null_mod_score_fit$deviance, alt_mod_score_fit$deviance),
  Df = c(null_mod_score_fit$df.residual, alt_mod_score_fit$df.residual),
  AIC = c(aic_null, aic_alt),
  BIC = c(bic_null, bic_alt)
)
drop_in_deviance <- tibble(
  Test = "Drop-in-deviance (Chi-sq)",
  G_stat = dev_test$Deviance[2],
  df = dev_test$Df[2],
  p_value = dev_test$`Pr(>Chi)`[2]
)
```

```{r, echo=FALSE, tab.cap="Alternative and null model comparison in terms of deviance, AIC, and BIC"}
kable(model_comparison, digits = 2)
```

Based on the output, we determine that the alternative model (i.e. the one with demographic information) performs significantly better exhibiting lower deviance, AIC, but also surprisingly BIC, which considers its additional complexity. This is quite surprising also considering that ethnicity is a variable with 10 different levels, and we would expect a large penalty for this complexity.

```{r, echo=FALSE, tab.cap="Drop-in-deviance test result for alternative and null models"}
kable(drop_in_deviance, digits = 4)
```

The drop-in-deviance tests corroborates that these results are statistically significant and that we can reject the null hypothesis since the p-value is less than 0.05. Hence, the alternative model will be further assessed as a means of identifying how demographic data affects the odds of a positive screening test. \newpage

**III. Results**

```{r, echo=FALSE, tab.cap="Output for alternative model"}
tidy(alt_mod_score_fit) |>
  kable(digits = 3)
```

The intercept for this model represents that, for a female individual who identifies as White-European did not have neonatal jaundice, we expect the odds of being classified as high probability for autism are 0.922, calculated from exp(-0.081). We however note a large p-value of 0.625, indicating a strong level of uncertainty of the truth of this expectation.

Among demographic predictors, people who identify as Asian, Middle Eastern, or South Asian are significantly less likely to be categorized as high probability for ASD with odd ratios (ORs) of approximately 0.182, 0.113, and 0.111 respectively, compared to the baseline category of White-European. We also observe that the Pasifika population has a notable odds ratio, but was once again a rather small group of less than 30 individuals and may prove difficult to generalize. In individuals with neonatal jaundice, we also observe that we expect the odds to multiply by a factor of 1.90 compared to those without, holding all else constant – indicating a positive association between this condition and receiving a positive screening test.

```{r, echo=FALSE, message = FALSE, fig.height = 4.5, fig.width = 10.5}
pred_prob <- predict.glm(alt_mod_score_fit, type = "response")

# Augment model with prediction and correct factor levels
alt_mod_score_fit_aug <- augment(alt_mod_score_fit) |>
  mutate(
    highProb = factor(highProb, levels = c(0, 1))  # 0 = non-event, 1 = event
  ) |>
  bind_cols(pred_prob = pred_prob)

# Calculate ROC data
roc_curve <- alt_mod_score_fit_aug |>
  roc_curve(highProb, pred_prob, event_level = "second")

# Calculate AUC
auc_val <- alt_mod_score_fit_aug |>
  roc_auc(highProb, pred_prob, event_level = "second") |>
  pull(.estimate)

# Plot ROC curve and annotate AUC
autoplot(roc_curve) +
  ggtitle("ROC Curve with AUC") +
  annotate("text", x = 0.65, y = 0.15, label = paste("AUC =", round(auc_val, 3)), size = 5)
```

The area under the curve is 0.74, which means that the model, although not a terrible fit, is not particularly remarkable. However, for a model fitted entirely to demographic data which we would normally expect to be independent of one's diagnosis, this could be considered a notable result.

**IV. Discussion + Conclusion**

Our model uses demographic data such as ethnicity, gender, and neonatal jaundice to predict the likelihood of a positive screening test for ASD, for this given questionnaire examining a variety of behaviors.

For model assumptions, logistic regression requires the assumption of log-odds possessing linearity, randomness, and independence of observations. It is worth noting that of these conditions, randomness is unlikely to be satisfied due to the nature of the data set – it was collected by people who already were likely to suspect an ASD diagnosis, as they are those who took the test voluntarily. However, our other two assumptions are likely to hold for this model, and we still determine our questions, model, and results worth further investigation. We do not need to check linearity as none of our predictors are quantitative. We can also assume independence as there are no anticipated temporal or spatial relationships between individuals taking the questionnaire.

Despite a low to moderate AUC value of 0.74, the classification power of the model is notable given the circumstances. Nevertheless, this indicates that further investigation into how the AQ10 may over- or under-diagnose certain population demographics could still be worth pursuing. This is especially true given that the odds of a positive test appear notably higher for individuals that identify as White, Black, and Hispanic – which could either indicate over-diagnosis of these groups or under-diagnosis of others. Presence of neonatal jaundice could also potentially serve as an additional reason to screen and test individuals. Thus, broader comparisons on the impact of these demographics would be insightful.

\newpage

**V. References**

-   Aishworiya, R., Kim, V., MA, Stewart, S., Hagerman, R., & Feldman, H. M. (2023). Meta-analysis of the Modified Checklist for Autism in Toddlers, Revised/Follow-up for Screening. *PEDIATRICS*, *151*(6). https://doi.org/10.1542/peds.2022-059393

-   Curnow, E., Utley, I., Rutherford, M., Johnston, L., & Maciver, D. (2023). Diagnostic assessment of autism in adults – current considerations in neurodevelopmentally informed professional learning with reference to ADOS-2. *Frontiers in Psychiatry*, *14*. https://doi.org/10.3389/fpsyt.2023.1258204

-   Hirota, T., & King, B. H. (2023). Autism spectrum Disorder. *JAMA*, *329*(2), 157. https://doi.org/10.1001/jama.2022.23661

-   Marin, Z. (2021, April 26). GLM fit: Algorithm did not converge – How to fix it. Statology. https://www.statology.org/glm-fit-algorithm-did-not-converge/

-   finnstats. (2021, May 14). Principal component analysis (PCA) in R. https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/

-   Szczęsna, K. (2022). PCA in R. RPubs. https://rpubs.com/KarolinaSzczesna/862710

\newpage

**V. Additional Materials**

Distribution of Y/N responses for Q1-10. The questions are the following: Q1, noticing small sounds; Q2, finding it difficult to work out character intentions; Q3, finding it easy to read between lines; Q4, big picture-oriented; Q5, can tell if someone listening to me is bored; Q6, can multitask; Q7, can tell feelings from faces; Q8, can go back to work when interrupted; Q9, enjoy collecting info on categories;Q10, find it difficult to work out people's intentions.
