---
title: "Written Report on Factors that Help Diagnose Autism"
author: "The Repos - Jeffrey Bohrer, Alexandra Green, Anna Zhang, Kevin Lee"
date: "March 20, 2025"
format: pdf
editor: visual
---

```{r, echo=FALSE, message = FALSE}
library(tidyverse)
library(tidymodels)
library(patchwork)
library(knitr)
library(tibble)
library(kableExtra)
library(glmnet)
library(pROC)
library(car)
library(corrplot)
library(ggcorrplot)
library(Stat2Data)  
library(broom)#empirical logit plots

autism_ds <- read_csv("data/autism_ds.csv") %>%
  mutate(ethnicity = ifelse(ethnicity == "others", "Others", ethnicity))
```

**I. Introduction**

Autism Spectrum Disorder (ASD) remains a highly prevalent condition despite modern strides made in medical technology. It is reported that nearly 2.2% of adults are affected by ASD, and growing awareness has led to an uptick in diagnoses, particularly in adults who went undiagnosed early in life (Hirota 2023). However, ASD screening tests for all age groups currently contain significant inaccuracies. For example, the most widely used toddler screening test, CHAT-R/FAs, was recently found to produce false negatives in 25% of cases. In contrast, the most commonly used adult autism screening test – the Autism-Spectrum Quotient (AQ) – was found to have limited predictive value in certain populations (Aishworiya 2023; Curnow 2023). Therefore, it has become critical to identify stronger predictors or explore underlying relationships to have more accurate tests and models to predict ASD in adults.

In this study, we will focus on identifying the features that most greatly affect the probability of being encouraged to pursue a diagnosis within this particular questionaire, as created by Prof. Fadi Thabtau of the Manukau Institute of Technology. The data was sourced from users of his app, ASDTests, which screens its users for potential indicators of autism using a ten-question survey. The data set being used will contain ten characteristics along with the answers of each individual to this survey. Because ASD is difficult to identify and can significantly impair an individual's quality of life, understanding the relationship between demographics, certain behaviors, and their association with autism could encourage individuals to seek diagnosis and gain the self-understanding they need. These adults who receive a positive diagnosis can then access the necessary resources for support. Our goal is to identify which aspects of this questionnaire are most closely associated with being encouraged to pursue an autism diagnosis.

For these purposes, both univariate and exploratory data analyses will be pursued as a means of assessing relevant avenues for further investigation and model fitting. These can be appreciated in the following pages. \newpage 

**i. Univariate EDA**

```{r, include =FALSE}
as.data.frame(as.matrix(summary(autism_ds$result)))%>%
  kable(digits = 3)
prop_high_scores <- nrow(autism_ds[autism_ds$'Class/ASD' == 'YES', ])/nrow(autism_ds)
cat("Proportion of scores indicative:", round(prop_high_scores, 3), "\n")
```

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of total scores across dataset", fig.height=1.5, fig.width=5.5}
autism_ds |>
  ggplot(aes(x = result)) +
  geom_bar(fill = "skyblue") +
  scale_x_continuous(breaks = seq(0, 10, 1), 
                     labels = as.character(seq(0, 10, 1))) +
  labs(x = "Score",
       y = "Count",
       title = "Score Distribution") + 
  theme_minimal()
```

As we can see in a quick summary of our data, the variable we are most interested in – the final score of users – ranges from 0 to 10, which makes sense as 10 questions can be answered either 'Yes' or 'No'. Generally, the scores are a bit right-skewed, with a single peak around 4 or 5 points. The mean score is 5.077, and the median is 5, both of which are relatively high considering that scores above 6 warrant further diagnostic evaluation. However, because suspecting a diagnosis is a reason for taking the test to begin with, these statistics are reasonable reflections of the test-taking population. We also observe that roughly 30% of test takers are encouraged to seek a diagnosis due to a score higher than 6, as calculated above. We also observe the IQR to be 4 points, as most test takers have a score between 3 and 7 points inclusive. In the context of the data, such a spread is reasonable, and no outliers exist which is understandable given the limited range of scores.

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of ethnicities across dataset", fig.height=2.5, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  ggplot(aes(x = fct_infreq(ethnicity))) +
  geom_bar(fill = "skyblue") +
  labs(x = "Ethnicity",
       y = "Count",
       title = "Distribution of Ethnicity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We observe here that the most common ethnicity was White-Europeans, with over 200 observations in our dataset. Secondly and thirdly, we observe the Asian and Middle Eastern populations to be above 100 and slightly below 100 observations, respectively. All other ethnicities have fewer than 50 observations in our data set, suggesting it may be more difficult to conclude about these populations. We can now check whether the proportion of individuals encouraged to seek a diagnosis varies by ethnicity:

```{r, echo=FALSE, message = FALSE, fig.cap="Proportion of indicative score across ethnicities", fig.height=2.5, fig.width=5.5}
autism_ds %>%
  group_by(ethnicity) %>%
  summarize(yes_count = sum(`Class/ASD` == "YES"),
            total_count = n(),
            proportion_yes = yes_count / total_count) %>%
  ggplot(aes(x = fct_reorder(ethnicity, proportion_yes, .desc=TRUE), y = proportion_yes)) +
  geom_col(fill = "skyblue") +
  labs(x = "Ethnicity",
       y = "Proportion
       High Test Scores",
       title = "Proportion of Indicative Test Scores by Ethnicity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

As we can see here, the population with the highest proportion of test takers receiving a high test score was the Latino population, with close to half achieving a score higher than a 6. Since this is a comparably uncommon population in our data set, it does raise questions of whether it is indicative of the greater Latino population or merely due to the smaller sample size in our data set. Additionally, the White-European, Black, and Hispanic populations also demonstrate a greater proportion of high test scores. The variation in these proportions according to ethnicity also warrants further exploration into how the distribution of test scores differs by ethnicity. Specifically, the questions remain of whether this means the rates of under- or over-diagnosis vary for different ethnic groups, and if so, what alterations would be necessary to ameliorate these errors.

```{r, include = FALSE}
summary(autism_ds$age)
```

```{r, echo=FALSE, message = FALSE, warning=FALSE, fig.cap="Age distribution across dataset", fig.height=1.6, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  ggplot(aes(x = age)) +
  geom_bar(fill = "skyblue") +
  labs(x = "Age",
       y = "Count",
       title = "Distribution of Age") +
  xlim(10, 75) + 
  theme_minimal()
```

Generally, we observe the distribution of ages to possess a strong right-skewness, with a mean age of 30.22 and a median age of 27. There is a clear peak in the age distribution roughly around the early to mid-20s. The ages range from a minimum of 17 to a maximum of 383 – a false observation that should be filtered from the data. The IQR is 13 years, which is a fairly small spread given the range of ages, as we observe that the majority of test-takers are under 30 years old.

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of Y/N responses for Q1-10. The questions are the following: Q1, noticing small sounds; Q2, finding it difficult to work out character intentions; Q3, finding it easy to read between lines; Q4, big picture-oriented; Q5, can tell if someone listening ot me is bored; Q6, can multitask; Q7, can tell feelings from faces; Q8, can go back to work when interrupted; Q9, enjoy collecting info on categories;Q10, find it difficult to work out people's intentions.", fig.height=1.5, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  mutate(
    small_sounds = if_else(small_sounds == 1, "Yes", "No"),
    difficult_to_understand_char = if_else(difficult_to_understand_char == 1, "Yes", "No"),
    ease_to_read_between_lines = if_else(ease_to_read_between_lines == 1, "Yes", "No"),
    focus_on_whole_picture = if_else(focus_on_whole_picture == 1, "Yes", "No"),
    i_can_tell_if_someone_bored = if_else(i_can_tell_if_someone_bored == 1, "Yes", "No"),
    i_can_multi_task = if_else(i_can_multi_task == 1, "Yes", "No"),
    i_can_tell_feelings_from_faces = if_else(i_can_tell_feelings_from_faces == 1, "Yes", "No"),
    i_can_go_back_to_work_when_interrupted = if_else(i_can_go_back_to_work_when_interrupted == 1, "Yes", "No"),
    i_like_to_collect_info_on_categories = if_else(i_like_to_collect_info_on_categories == 1, "Yes", "No"),
    i_find_it_hard_to_figure_out_others_intentions = if_else(i_find_it_hard_to_figure_out_others_intentions == 1, "Yes", "No")
  ) |>
  rename(
    `Q1` = small_sounds,
    `Q2` = difficult_to_understand_char,
    `Q3` = ease_to_read_between_lines,
    `Q4` = focus_on_whole_picture,
    `Q5` = i_can_tell_if_someone_bored,
    `Q6` = i_can_multi_task,
    `Q7` = i_can_tell_feelings_from_faces,
    `Q8` = i_can_go_back_to_work_when_interrupted,
    `Q9` = i_like_to_collect_info_on_categories,
    `Q10` = i_find_it_hard_to_figure_out_others_intentions
  ) |>
  select("Q1":"Q10") |>
  pivot_longer(everything(), names_to = "question", values_to = "response") |>
  mutate(
    question = factor(question, levels = paste0("Q", 1:10))  
  ) |>
  ggplot(aes(x = question, fill = response)) +
  geom_bar(position = "fill") +
  labs(
    x = "Question",
    y = "Proportion",
    title = "Distribution of Yes/No Responses to Autism Screening Questions",
    fill = "Response"
  ) +
  scale_fill_brewer(palette = "Blues") +
  theme_minimal()
```

The two questions with the highest proportion of "Yes" responses were Q1 and Q8, suggesting that these behaviors are common among respondents. On the other hand, Q6 and Q9 had noticeably lower "Yes" responses, potentially indicating difficulties in such areas. Most questions, however, had roughly even proportions between "Yes" and "No" responses.

**ii. Bivariate EDA**

```{r, echo=FALSE, message = FALSE, warning = FALSE, fig.cap="Score distribution across ethnicities", fig.height=2.25, fig.width=5.5}
### Result score distributions by ethnicity
ggplot(autism_ds, 
       aes(y = result,
           x = ethnicity,
           fill = ethnicity)) +
  geom_boxplot() +
  labs(
    title = "Scores Distributions Across Ethnicity",
    y = "Score",
    fill = "Ethnicity",
    x = ""
  )  +
  scale_fill_brewer(palette = "Blues", guide = "none")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Here we present several graphs displaying bivariate relationships. With our first set of box plots, we find further evidence for our previous suspicion that test score distributions differ by ethnicity. Although most ethnicities have a median within the range of roughly 3 to 6, some ethnicities, like the White-European, Black, and Hispanic populations, demonstrate a greater spread through their larger IQRs, while the Turkish, Middle Eastern, and Asian populations are much more concentrated around their medians. However, most ethnicities appear to have values almost entirely across the range of 0 to 10 in their test scores.

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of scores by respondent type", fig.height=2, fig.width=5.5}
ggplot(autism_ds, 
       aes(y = result,
           x = relation,
           fill = relation)) +
  geom_violin(alpha = 0.5) +
  labs(
    title = "Score Distribution by Respondent Type",
    y = "Score",
    x = "Relation"
  ) +
  scale_fill_brewer(palette = "Blues", guide = "none") +
  theme_minimal()

```

Interestingly, we can also observe how the relationship between the test taker and the subject of the questions may lead to different distributions of test scores. In the case when it is filled out by a relative or health care professional for example, the observed test score is 2 or greater, while in the case of the test taker being the subject or the parent of the subject, some still received a score of 0. This could reflect how personal biases or relationships affect truthfulness during the test.

This initial exploration leads us to investigate one of these questions further, and particularly how our demographic data may impact the probability of being encouraged to seek a formal diagnosis. Though we cannot identify a definitive answer of whether it is due to social or cultural perceptions of autism within these subgroups or true difference in rates of its presence, it is worth identifying whether over- or under-diagnosis for certain subgroups is possible.

**II. Methodology**

**i. Choosing Predictors**

Firstly, a drop-in-deviance test between a logistic null model without predictor variables and a logistic model with a single predictor was systematically conducted across ethnicity, gender, presence of neonatal jaundice, and relationship as a means of assessing which predictors provide a statistically significant improvement in model fit against the null condition.These were chosen first due to their "less direct" relationship with diagnosis. The hypothesis for this test can be observed below, where $\beta_1$ represents the coefficient for the associated predictor variable: $$H_0: \beta_1 = 0$$ $$H_a: \beta_1 \neq 0$$ The formulas for the models compared are the following: $$Null:log(\frac{\hat\pi}{1-\hat\pi})=\beta_0$$ $$Alternative:log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_{predictor}x_{predictor}$$ The following table summarizes the results

```{r, include = FALSE}
#TO-DO: check for redundancy of mutating the highProb column and the usage of the reduced model for some of our features

### Ethnicity DD
autism_ds <- autism_ds %>%
  mutate(highProb = if_else(result > 6, 1, 0))

reduced_model <- glm(highProb ~ 1, 
              data = autism_ds, family = "binomial")
ethnicity_model <- glm(highProb ~ ethnicity, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_eth <- -2 * glance(ethnicity_model)$logLik), "\n")
cat("G-stat:", (G_eth <- deviance_reduced - deviance_eth), "\n")
cat("p-value:", pchisq(G_eth, df = 9, lower.tail = FALSE), "\n")

tidy(ethnicity_model) |>
  kable(digits = 3)
```

```{r, include =FALSE}
### Relation DD

relation_model <- glm(highProb ~ relation, 
              data = autism_ds, family = "binomial")

cat("D-reduced:",(deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-fulll:",(deviance_rel <- -2 * glance(relation_model)$logLik), "\n")
cat("G-stat:",(G_rel<- deviance_reduced - deviance_rel), "\n")
cat("p-value:",pchisq(G_rel, df = 4, lower.tail = FALSE), "\n")

tidy(relation_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
## Age
reduced_model <- glm(highProb ~ 1, 
              data = autism_ds, family = "binomial")
age_model <- glm(highProb ~ age, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_age <- -2 * glance(age_model)$logLik), "\n")
cat("G-stat:", (G_age <- deviance_reduced - deviance_age), "\n")
cat("p-value:", pchisq(G_age, df = 1, lower.tail = FALSE), "\n")

tidy(age_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
### Gender
gender_model <- glm(highProb ~ gender, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_gender <- -2 * glance(gender_model)$logLik), "\n")
cat("G-stat:", (G_gender <- deviance_reduced - deviance_gender), "\n")
cat("p-value:", pchisq(G_gender, df = 1, lower.tail = FALSE), "\n")

tidy(gender_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
### Jaundice
jaundice_model <- glm(highProb ~ jundice, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_j <- -2 * glance(jaundice_model)$logLik), "\n")
cat("G-stat:", (G_j <- deviance_reduced - deviance_j), "\n")
cat("p-value:", pchisq(G_j, df = 1, lower.tail = FALSE), "\n")

tidy(jaundice_model) |>
  kable(digits = 3)
```

```{r, message=FALSE, echo =FALSE, tab.cap="Non-obvious predictors drop-in-deviance test results" }
header <- c("Deviance", "G statistic (respect to null)", "p-value")
Null <- c(round(deviance_reduced, 3), "NA", "NA")

Ethnicity <- c(round(deviance_eth, 3), round(G_eth,3), round(pchisq(G_eth, df = 9, lower.tail = FALSE),5))
Relation <- c(round(deviance_rel,3), round(G_rel,3), round(pchisq(G_rel, df = 4, lower.tail = FALSE),3))
Age <- c(round(deviance_age,3), round(G_age,3), round(pchisq(G_age, df = 1, lower.tail = FALSE),3))
Gender <- c(round(deviance_gender,3), round(G_gender,3), round(pchisq(G_gender, df = 1, lower.tail = FALSE),3))
Jaundice <- c(round(deviance_j,3), round(G_j,3),  round(pchisq(G_j, df = 1, lower.tail = FALSE),3))

non_obvious_pred <- rbind(Null, Ethnicity, Relation, Age, Gender, Jaundice)
colnames(non_obvious_pred) <- header

kable(non_obvious_pred)
```

From the results of this test, it is evident that the parameters that are statistically significant for model fit are ethnicity, gender, and, quite surprisingly, neonatal jaundice when compared to a null model as the p-values are either significantly less than 0.05 (as in ethnicity) or slightly below it (gender and jaundice). We further investigate the correlation between answers to questions below, as a means of assessing if the test has any pitfalls regarding multicollinearity:

```{r, echo=FALSE, message = FALSE, fig.cap = "Correlation between AQ10 questions", fig.height=2.75, fig.width=10.5}
q1_to_10 <- autism_ds |>
  select(small_sounds, difficult_to_understand_char,
         ease_to_read_between_lines,
         focus_on_whole_picture,
         i_can_tell_if_someone_bored,
         i_can_multi_task,
         i_can_tell_feelings_from_faces,
         i_can_go_back_to_work_when_interrupted,
         i_like_to_collect_info_on_categories,
         i_find_it_hard_to_figure_out_others_intentions)

cor_matrix <- cor(q1_to_10, method = "pearson", use = "complete.obs")

short_names <- c(
  "Q1", "Q2", "Q3", "Q4", "Q5",
  "Q6", "Q7", "Q8", "Q9", "Q10"
)

colnames(cor_matrix) <- short_names
rownames(cor_matrix) <- short_names

corrplot(cor_matrix,
         method = "color",
         type = "upper",
         tl.col = "black",
         tl.cex = 1,
         addCoef.col = "black",
         number.cex = 0.7,
         diag = FALSE)
```

By computing a correlation heat map among the ten behavior questions to check multicollinearity, we note that surprisingly, only a few questions have stronger correlations with one another. This is rather unexpected since we would expect many behaviors to be grouped together and more correlated (e.g., social behaviors). However, the highest correlation is between questions 6 and 9, which are the questions about multitasking and liking to collect information, respectively – this is also a rather surprising pairing. Due to this, Q3, Q5 and Q6 will be disregarded from modeling purposes as they showcase correlation with Q4, Q9, and Q10.

Considering this reality, principal component analysis was employed as a means of determining the question clusters that explain the highest variance and selecting the most significant in terms of loading for later inclusion in models (Szczęsna, 2022; finnstats, 2021).
```{r, include=FALSE}
pca <- prcomp(autism_ds |>
     rename(
        `Q1` = small_sounds,
        `Q2` = difficult_to_understand_char,
        `Q3` = ease_to_read_between_lines,
        `Q4` = focus_on_whole_picture,
        `Q5` = i_can_tell_if_someone_bored,
        `Q6` = i_can_multi_task,
        `Q7` = i_can_tell_feelings_from_faces,
        `Q8` = i_can_go_back_to_work_when_interrupted,
        `Q9` = i_like_to_collect_info_on_categories,
        `Q10` = i_find_it_hard_to_figure_out_others_intentions
    ) |> select(Q1:Q10), center = TRUE, scale. = TRUE)
summary(pca)
# Loadings reshaped
loadings_df <- as.data.frame(pca$rotation[, 1:10]) |>
  rownames_to_column("question") |>
  pivot_longer(cols = -question, names_to = "PC", values_to = "loading")

# Keep question and PC order fixed
loadings_df$question <- factor(loadings_df$question, levels = paste0("Q", 1:10))
loadings_df$PC <- factor(loadings_df$PC, levels = paste0("PC", 1:10))
```

```{r, echo=FALSE, fig.cap = "Principal component analysis Q1-10 as a means of choosing questions that best explain the variance in the response", fig.height=6, fig.width=10.5}
# Plot
ggplot(loadings_df, aes(x = question, y = abs(loading), fill = PC)) +
  geom_col(position = "dodge") +
  coord_flip() +
  facet_wrap(~ PC, scales = "free_y") +
  labs(title = "PCA Loadings by Question", x = "Question", y = "Loading") +
  scale_fill_discrete(guide = "none") +
  theme_minimal()
```
Ignoring questions 3, 5, and 6 due to issues with correlation, the questions that imply the most loading for principal components (i.e. the parameters that explain the most variance) are Q10, Q8, Q4, Q2, and Q1. Higher priority was given to questions that load the highest for the first 7 principal components, as these explain ~83% of variance in the response. Due to this, the answers to these questions will be employed as predictors (i.e finding it hard to figure out others intentions, ease of going back to work when interrupted, focus on whole picture, difficulty to understand characters in stories, and picking up on small sounds). \newpage

**ii. Fitting the Model**

Considering the two "groups" of variables we are working with: question answers and demogrpahic information. Two models will be fitted and compared in terms of a drop-in-deviance test: (a) a model that only accounts for the answers to the questions and (b) a model that accounts for demographic data on top of the previously selected questions. Subsequently, the models fitted will be of the forms:
$$Null:log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_{Q1}X_{Q1} + \beta_{Q2}X_{Q2}+ \beta_{Q4}X_{Q4} + \beta_{Q8}X_{Q8} + \beta_{Q10}X_{Q10}$$
$$Alternative:log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_{Q1}X_{Q1} +\beta_{Q2}X_{Q2}+ \beta_{Q4}X_{Q4} + \beta_{Q8}X_{Q8} + \beta_{Q10}X_{Q10} + \newline \beta_{ethnicity}X_{ethnicity}+\beta_{gender}X_{gender}+\beta_{jaundice}X_{jaundice}$$
Subsequently, the hypotheses for the test will be the following:
$$H_0: \beta_{ethnicity}=\beta_{gender}=\beta_{jaundice}=0$$
$$H_a: \beta_{ethnicity}, \beta_{gender}, \beta_{jaundice}\neq0 \space, for \space one \space \beta_j$$
This is to assess whether demographic predictors significantly improve model fit with respect to predictors that most significantly explain the variability in final score and, ultimately, diagnosis. Additionally, AIC and BIC were included for additional comparison.

```{r, include = FALSE}
autism_ds$ethnicity <- relevel(factor(autism_ds$ethnicity), ref = "White-European")
null_mod_score_fit <- glm(highProb ~ small_sounds +
                            difficult_to_understand_char +
                            focus_on_whole_picture +
                            i_can_go_back_to_work_when_interrupted +
                            i_find_it_hard_to_figure_out_others_intentions, 
                            data = autism_ds, family = "binomial")

alt_mod_score_fit <- glm(highProb ~ small_sounds +
                            difficult_to_understand_char +
                            focus_on_whole_picture +
                            i_can_go_back_to_work_when_interrupted +
                            i_find_it_hard_to_figure_out_others_intentions +
                            ethnicity + 
                            gender +
                            jundice,
                            data = autism_ds, family = "binomial")

dev_test <- anova(null_mod_score_fit, alt_mod_score_fit, test = "Chisq")

aic_null <- AIC(null_mod_score_fit)
bic_null <- BIC(null_mod_score_fit)
aic_alt <- AIC(alt_mod_score_fit)
bic_alt <- BIC(alt_mod_score_fit)

model_comparison <- tibble(
  Model = c("Null Model", "Alternative Model"),
  Residual_Deviance = c(null_mod_score_fit$deviance, alt_mod_score_fit$deviance),
  Df = c(null_mod_score_fit$df.residual, alt_mod_score_fit$df.residual),
  AIC = c(aic_null, aic_alt),
  BIC = c(bic_null, bic_alt)
)
drop_in_deviance <- tibble(
  Test = "Drop-in-deviance (Chi-sq)",
  G_stat = dev_test$Deviance[2],
  df = dev_test$Df[2],
  p_value = dev_test$`Pr(>Chi)`[2]
)
```

```{r, echo=FALSE, tab.cap="Alternative and null model comparison in terms of deviance, AIC, and BIC"}
kable(model_comparison, digits = 2)
```
It is evident that the alternative model (i.e. the one that account for demographic information on top of question data) performs significantly better exhibiting lower deviance, AIC. Nevrtheless, the BIC is higher. This is, however expected given the number of predictors as ethnicity is a categorical variable with 10 levels. 
```{r, echo=FALSE, tab.cap="Drop-in-deviance test result for alternative and null models"}
kable(drop_in_deviance, digits = 4)

```
The drop-in-deviance tests corroborates that these results are statistically significant and that we can reject the null hypothesis since the p-value is less than 0.05. Hence, the alternative model will be further assessed.

```{r, echo=FALSE, tab.cap="Output for alternative model"}
tidy(alt_mod_score_fit) |>
  kable(digits = 3)
```
The intercept for this model represents that, for an individual who answered no to all the AQ10 questions relevant to the model, who identifies as White-European, is female and did not have neonatal jaundice the odds of being classified as high probability for autism are `r round(exp(-7.906), 3)`.

The estimates for the AQ10 showcase strong statistical associations with higher odds of ASD. Holding all else constant, individuals who reported picking up on small sounds have odds of being characterized as high probability for ASD increase by a factor of `r round(exp(2.26), 3)`. Likewise, difficulty understanding character intentions (OR =  `r round(exp(1.695), 3)`), tendency to focus on whole picture (OR =  `r round(exp(2.636), 3)`), ease of going back to work when interrupted (OR =  `r round(exp(1.761), 3)`),finding it hard to understand others' intentions (OR =`r round(exp(2.228), 3)`) all strongly predict ASD. 

Among demographic predictors, it is evident that people who identify as Asian, Middle Eastern, or South Asian are significantly less likely to be categorized as high probability for ASD woth odd ratios (ORs) of approximately 0.42, 0.28, and 0.21 respectively. On the other hand those identifying as Black, Hispanic, Latino, Psifika, Turkish, or "Others" do not significantly alter the odds. \newpage

**III. Results**

```{r, echo=FALSE, message = FALSE}
pred_prob <- predict.glm(alt_mod_score_fit, type = "response")

# Augment model with prediction and correct factor levels
alt_mod_score_fit_aug <- augment(alt_mod_score_fit) |>
  mutate(
    highProb = factor(highProb, levels = c(0, 1))  # 0 = non-event, 1 = event
  ) |>
  bind_cols(pred_prob = pred_prob)

# Calculate ROC data
roc_curve <- alt_mod_score_fit_aug |>
  roc_curve(highProb, pred_prob, event_level = "second")

# Calculate AUC
auc_val <- alt_mod_score_fit_aug |>
  roc_auc(highProb, pred_prob, event_level = "second") |>
  pull(.estimate)

# Plot ROC curve and annotate AUC
autoplot(roc_curve) +
  ggtitle("ROC Curve with AUC") +
  annotate("text", x = 0.65, y = 0.15, label = paste("AUC =", round(auc_val, 3)), size = 5)
```

The area under the curve is 0.934, which for a model fitted to demographic data and questionaire data. This is really impressive, however over-fitting is certainly a concern. Nevertheless, this indicates that further investigation into how these the AQ10 may over- or under-diagnose certain population demographics could still be worth pursuing. Thus, broader comparisons would be extremely interesting. 

For model assumptions, logistic regression requires the assumption of log-odds possessing linearity, randomness, and independence of observations. It is worth noting that of these conditions, randomness is unlikely to be satisfied due to the nature of the data set – it was collected by people who already were likely to suspect an ASD diagnosis, as they are those who took the test voluntarily. However, our other two assumptions are likely to hold for this model, and we still determine our questions, model, and results worth further investigation. We do not need to check linearity as none of our predictors are quantitative. We can also assume independence as there are no anticipated temporal or spatial relationships between individuals taking the questionnaire.

Once more, a .934 AUC for a model that only accounts for 5 questions of the test and demographic data showcases that further analysis should be pursued to assess whether the test is biased towards certain populations. This is especially true given that the odds are notably high for individuals that identify as White-European. \newpage

**IV. References**

-   Aishworiya, R., Kim, V., MA, Stewart, S., Hagerman, R., & Feldman, H. M. (2023). Meta-analysis of the Modified Checklist for Autism in Toddlers, Revised/Follow-up for Screening. *PEDIATRICS*, *151*(6). https://doi.org/10.1542/peds.2022-059393

-   Curnow, E., Utley, I., Rutherford, M., Johnston, L., & Maciver, D. (2023). Diagnostic assessment of autism in adults – current considerations in neurodevelopmentally informed professional learning with reference to ADOS-2. *Frontiers in Psychiatry*, *14*. https://doi.org/10.3389/fpsyt.2023.1258204

-   Hirota, T., & King, B. H. (2023). Autism spectrum Disorder. *JAMA*, *329*(2), 157. https://doi.org/10.1001/jama.2022.23661

-   Marin, Z. (2021, April 26). GLM fit: Algorithm did not converge – How to fix it. Statology. https://www.statology.org/glm-fit-algorithm-did-not-converge/

- finnstats. (2021, May 14). Principal component analysis (PCA) in R. https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/

- Szczęsna, K. (2022). PCA in R. RPubs. https://rpubs.com/KarolinaSzczesna/862710

::: Before you submit, make sure your code chunks are turned off with `echo: false` and there are no warnings or messages with `warning: false` and `message: false` in the YAML. ::: 

\newpage

**V. Additonal Materials**

