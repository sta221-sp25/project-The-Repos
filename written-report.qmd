---
title: "An Investigation of Demographic and Behavioral Factors of Autism Screening Tests"
author: "The Repos - Jeffrey Bohrer, Alexandra Green, Anna Zhang, Kevin Lee"
date: "April 28, 2025"
format: pdf
editor: visual
---

```{r, echo=FALSE, message = FALSE}
library(tidyverse)
library(tidymodels)
library(patchwork)
library(knitr)
library(tibble)
library(kableExtra)
library(glmnet)
library(pROC)
library(car)
library(corrplot)
library(ggcorrplot)
library(Stat2Data)  
library(broom)#empirical logit plots

autism_ds <- read_csv("data/autism_ds.csv") %>%
  mutate(ethnicity = ifelse(ethnicity == "others", "Others", ethnicity))
autism_ds <- autism_ds %>%
  filter(age < 120)
```

**I. Introduction**

Autism Spectrum Disorder (ASD) is a highly prevalent condition with nearly 2.2% of adults affected by ASD, and growing awareness has led to an uptick in diagnoses, particularly in adults who went undiagnosed early in life (Hirota 2023). However, ASD screening tests for all age groups currently contain significant inaccuracies. For example, the most widely used toddler screening test, CHAT-R/FAs, was found to produce false negatives in 25% of cases; the most commonly used adult autism screening test – the Autism-Spectrum Quotient (AQ) – was found to have limited predictive value in certain populations (Aishworiya 2023; Curnow 2023). Thus, it is critical to identify stronger predictors and explore underlying relationships for more accurate tests to predict ASD in adults.

In this study, we will focus on identifying the features that most greatly affect the probability of being encouraged to pursue a diagnosis within a questionnaire created by Prof. Fadi Thabtah of the Manukau Institute of Technology. The data was sourced from users of his app, ASDTests, which screens its users for potential indicators of autism using a ten-question survey (Faizunnabi 2024; Thabtah 2017). The data set has over 600 observations and contains nine demographic characteristics – ranging from age to history of neonatal jaundice – along with the binary answers to the ten behavioral questions of this survey. An individual of 383 years old was observed as a clear data entry error, so we restricted age to under 120 years old to remove implausible ages. We relabeled the features representing behavioral questions in the data set with their actual wording for interpretability (such as renaming from Q6 to i_can_multitask), in addition to representing "Yes" as a 1 and "No" as a 0 for their values.

Because ASD is difficult to identify and can significantly impair an individual's quality of life, understanding the relationship between demographics, behaviors, and their association with autism could encourage individuals to seek the diagnosis they may need, which then enables access to the necessary resources for support. Accordingly, our research question is: what characteristics of an individual are most closely associated with a high score on this screening test? \newpage

**i. Univariate EDA**

```{r, include = FALSE}
as.data.frame(as.matrix(summary(autism_ds$result)))%>%
  kable(digits = 3)
prop_high_scores <- nrow(autism_ds[autism_ds$'Class/ASD' == 'YES', ])/nrow(autism_ds)
cat("Proportion of scores indicative:", round(prop_high_scores, 3), "\n")
```

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of total scores across dataset", fig.height=1.5, fig.width=5.5}
autism_ds |>
  ggplot(aes(x = result)) +
  geom_bar(fill = "skyblue") +
  scale_x_continuous(breaks = seq(0, 10, 1), 
                     labels = as.character(seq(0, 10, 1))) +
  labs(x = "Score",
       y = "Count",
       title = "Score Distribution") + 
  theme_minimal()
```

The final score of individuals ranges from 0 to 10 for each of the 10 behavioral questions. The mean score is 5.084, and the median is 5, which are relatively high considering that scores above 6 warrant further diagnostic evaluation. However, as suspecting a diagnosis is a reason for taking the test to begin with, these are reasonable reflections of the test-taking population. We also observe that roughly 29.6% of subjects are encouraged to seek a diagnosis due to a score higher than 6; the IQR is 4 points, as most subjects have a score between 3 and 7 points inclusive. In the context of the data, such a spread is reasonable, as no outliers exist.

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of ethnicities across dataset", fig.height=2, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  ggplot(aes(x = fct_infreq(ethnicity))) +
  geom_bar(fill = "skyblue") +
  labs(x = "Ethnicity",
       y = "Count",
       title = "Distribution of Ethnicity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

White-Europeans comprised the most common ethnicity of our respondents, with over 200 observations in our data set, while the Asian and Middle Eastern populations have over 100 and slightly below 100 observations, respectively. All other ethnicities have fewer than 50 observations in our data set, suggesting it may be more difficult to draw conclusions about those groups. We will later observe the differing score distributions as categorized by ethnicity to better understand the relationship between score and ethnicity.

```{r, include = FALSE}
summary(autism_ds$age)
```

```{r, echo=FALSE, message = FALSE, warning=FALSE, fig.cap="Age distribution across dataset", fig.height=1.5, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  ggplot(aes(x = age)) +
  geom_bar(fill = "skyblue") +
  labs(x = "Age",
       y = "Count",
       title = "Distribution of Age") +
  xlim(10, 75) + 
  theme_minimal()
```

The distribution of ages possesses a strong right-skewness, with a mean age of 29.63 and a median age of 27. There is a clear peak in the age distribution roughly around the early to mid-20s. The ages range from a minimum of 17 to a maximum of 64 years old. The IQR is 13 years, which is a fairly small spread given the range of ages, as the majority of test-takers are under 30 years old.

```{r, echo=FALSE, message = FALSE, fig.cap='Distribution of Y/N responses for Q1-10 (question details found in appendix).', fig.height=1.5, fig.width=5.5}
#|echo: false
#|warning: false
#|message: false
autism_ds |>
  mutate(
    small_sounds = if_else(small_sounds == 1, "Yes", "No"),
    difficult_to_understand_char = if_else(difficult_to_understand_char == 1, "Yes", "No"),
    ease_to_read_between_lines = if_else(ease_to_read_between_lines == 1, "Yes", "No"),
    focus_on_whole_picture = if_else(focus_on_whole_picture == 1, "Yes", "No"),
    i_can_tell_if_someone_bored = if_else(i_can_tell_if_someone_bored == 1, "Yes", "No"),
    i_can_multi_task = if_else(i_can_multi_task == 1, "Yes", "No"),
    i_can_tell_feelings_from_faces = if_else(i_can_tell_feelings_from_faces == 1, "Yes", "No"),
    i_can_go_back_to_work_when_interrupted = if_else(i_can_go_back_to_work_when_interrupted == 1, "Yes", "No"),
    i_like_to_collect_info_on_categories = if_else(i_like_to_collect_info_on_categories == 1, "Yes", "No"),
    i_find_it_hard_to_figure_out_others_intentions = if_else(i_find_it_hard_to_figure_out_others_intentions == 1, "Yes", "No")
  ) |>
  rename(
    `Q1` = small_sounds,
    `Q2` = difficult_to_understand_char,
    `Q3` = ease_to_read_between_lines,
    `Q4` = focus_on_whole_picture,
    `Q5` = i_can_tell_if_someone_bored,
    `Q6` = i_can_multi_task,
    `Q7` = i_can_tell_feelings_from_faces,
    `Q8` = i_can_go_back_to_work_when_interrupted,
    `Q9` = i_like_to_collect_info_on_categories,
    `Q10` = i_find_it_hard_to_figure_out_others_intentions
  ) |>
  select("Q1":"Q10") |>
  pivot_longer(everything(), names_to = "question", values_to = "response") |>
  mutate(
    question = factor(question, levels = paste0("Q", 1:10))  
  ) |>
  ggplot(aes(x = question, fill = response)) +
  geom_bar(position = "fill") +
  labs(
    x = "Question",
    y = "Proportion",
    title = "Distribution of Yes/No Responses to Screening Questions",
    fill = "Response"
  ) +
  scale_fill_brewer(palette = "Blues") +
  theme_minimal()
```

The two questions with the highest proportion of "Yes" responses were Q1 and Q8, suggesting that these behaviors are relatively common among respondents. On the other hand, Q6 and Q9 had noticeably lower "Yes" responses, potentially indicating difficulties in such areas. Other questions, however, had roughly even proportions of "Yes" and "No" responses. \newpage

**ii. Bivariate EDA**

```{r, echo=FALSE, message = FALSE, warning = FALSE, fig.cap="Score distribution across ethnicities", fig.height=2.25, fig.width=5.5}
### Result score distributions by ethnicity
ggplot(autism_ds, 
       aes(y = result,
           x = ethnicity,
           fill = ethnicity)) +
  geom_boxplot() +
  labs(
    title = "Scores Distributions Across Ethnicity",
    y = "Score",
    fill = "Ethnicity",
    x = ""
  )  +
  scale_fill_brewer(palette = "Blues", guide = "none")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Here we present several graphs displaying bivariate relationships. With our first set of box plots, we find further evidence for our previous suspicion that test score distributions differ by ethnicity. Although most ethnicities have a median within the range of roughly 3 to 6, some ethnicities, like the White-European, Black, and Hispanic populations, demonstrate a greater spread through their larger IQRs, while the Turkish, Middle Eastern, and Asian populations are much more concentrated around their medians.

```{r, echo=FALSE, message = FALSE, fig.cap="Distribution of scores by respondent type", fig.height=2, fig.width=5.5}
ggplot(autism_ds, 
       aes(y = result,
           x = relation,
           fill = relation)) +
  geom_violin(alpha = 0.5) +
  labs(
    title = "Score Distribution by Respondent Type",
    y = "Score",
    x = "Relation"
  ) +
  scale_fill_brewer(palette = "Blues", guide = "none") +
  theme_minimal()

```

Interestingly, we can observe how the relationship between the test taker and the subject appears to lead to differing distributions of test scores. When it is filled out by a relative or health care professional for example, the observed test score is 2 or greater, while in the case of the test taker being the subject or the parent of the subject, some still received a score of 0. We wonder if this could reflect how personal biases or relationships affect truthfulness during the test.

We choose to continue to investigate how our demographic data may impact the odds of being encouraged to seek a formal diagnosis as observed by a high score on this screening test. Though we cannot definitively answer whether it is due to social or cultural perceptions of autism within and surrounding these subgroups or true differences in rates of its presence, it is worth identifying whether over- or under-diagnosis for certain populations is more probable.

**II. Methodology**

**i. Choosing Predictors**

We aim to use predictors to determine the probability of obtaining a high score on the screening test. Therefore, we choose logistic regression as the model. Firstly, a drop-in-deviance test between a logistic null model without predictor variables and only an intercept, and a logistic model with a single predictor was systematically conducted across ethnicity, gender, presence of neonatal jaundice, and relationship to the subject as a means of assessing which predictors provide a statistically significant improvement in model fit against this null condition. Additionally, we also tested the interaction effects of these demographics; we note that we did not explore potential interactions with jaundice as a neonatal condition unlikely to have any relationship with the other variables. Additionally, we did not test ethnicity and relation's interaction effect due to the high number of levels for both (10 and 5, respectively), so the distribution of observations across these subgroups severely limits our sample sizes across coefficients. These tests were done to gain information on the relationship between demographic data and test scores. The hypothesis for this test can be observed below, where $\beta_{predictor}$ represents the coefficient for a single associated predictor variable (also noted for the case of a single-level variable): $$H_0: \beta_{predictor} = 0$$ $$H_a: \beta_{predictor} \neq 0$$ The formulas for the models compared are the following:$$\text{Null:}\; \log(\frac{\hat\pi}{1-\hat\pi})=\beta_0$$

$$\text{Alternative:} \; \log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_{predictor}x_{predictor}$$

Similarly, for our interaction effects, where $x_1, x_2$ are the predictors for which we test the interaction effect, again using the example of single-level variables:

$$H_0: \beta_{12} = 0$$ $$H_a: \beta_{12} \neq 0$$

$$\text{Null:} \; \log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_1x_1+\beta_2x_2$$ $$\text{Alternative:}\; \log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_{12}(x_1*x_2)$$

The following table summarizes these results.

```{r, include = FALSE}
### Ethnicity DD
autism_ds <- autism_ds %>%
  mutate(highProb = if_else(`Class/ASD` == "YES", 1, 0))

reduced_model <- glm(highProb ~ 1, 
              data = autism_ds, family = "binomial")
ethnicity_model <- glm(highProb ~ ethnicity, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_eth <- -2 * glance(ethnicity_model)$logLik), "\n")
cat("G-stat:", (G_eth <- deviance_reduced - deviance_eth), "\n")
cat("p-value:", pchisq(G_eth, df = 9, lower.tail = FALSE), "\n")

tidy(ethnicity_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
### Relation DD

relation_model <- glm(highProb ~ relation, 
              data = autism_ds, family = "binomial")

cat("D-reduced:",(deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-fulll:",(deviance_rel <- -2 * glance(relation_model)$logLik), "\n")
cat("G-stat:",(G_rel<- deviance_reduced - deviance_rel), "\n")
cat("p-value:",pchisq(G_rel, df = 4, lower.tail = FALSE), "\n")

tidy(relation_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
## Age
age_model <- glm(highProb ~ age, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_age <- -2 * glance(age_model)$logLik), "\n")
cat("G-stat:", (G_age <- deviance_reduced - deviance_age), "\n")
cat("p-value:", pchisq(G_age, df = 1, lower.tail = FALSE), "\n")

tidy(age_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
### Gender
gender_model <- glm(highProb ~ gender, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_gender <- -2 * glance(gender_model)$logLik), "\n")
cat("G-stat:", (G_gender <- deviance_reduced - deviance_gender), "\n")
cat("p-value:", pchisq(G_gender, df = 1, lower.tail = FALSE), "\n")

tidy(gender_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
### Jaundice
jaundice_model <- glm(highProb ~ jundice, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced <- -2 * glance(reduced_model)$logLik), "\n")
cat("D-full:", (deviance_j <- -2 * glance(jaundice_model)$logLik), "\n")
cat("G-stat:", (G_j <- deviance_reduced - deviance_j), "\n")
cat("p-value:", pchisq(G_j, df = 1, lower.tail = FALSE), "\n")

tidy(jaundice_model) |>
  kable(digits = 3)

```

```{r, include = FALSE}
# Relation/gender interaction model
reduced_rel_gen <- glm(highProb ~ relation + gender, 
              data = autism_ds, family = "binomial")
rel_gen_model <- glm(highProb ~ relation*gender, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced_rel_gen <- -2 * glance(reduced_rel_gen)$logLik), "\n")
cat("D-full:", (deviance_rel_gen <- -2 * glance(rel_gen_model)$logLik), "\n")
cat("G-stat:", (G_rel_gen <- deviance_reduced_rel_gen - deviance_rel_gen), "\n")
cat("p-value:", pchisq(G_rel_gen, df = 4, lower.tail = FALSE), "\n")

tidy(rel_gen_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
# gender/ethnicity interaction model
reduced_gen_eth_model <- glm(highProb ~ gender + ethnicity, 
              data = autism_ds, family = "binomial")
gen_eth_model <- glm(highProb ~ gender*ethnicity, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced_gen_eth <- -2 * glance(reduced_gen_eth_model)$logLik), "\n")
cat("D-full:", (deviance_gen_eth <- -2 * glance(gen_eth_model)$logLik), "\n")
cat("G-stat:", (G_gen_eth <- deviance_reduced_gen_eth - deviance_gen_eth), "\n")
cat("p-value:", pchisq(G_gen_eth, df = 9, lower.tail = FALSE), "\n")

tidy(gen_eth_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
# age / gender interaction model
reduced_gen_age_model <- glm(highProb ~ gender + age, 
              data = autism_ds, family = "binomial")
gen_age_model <- glm(highProb ~ gender*age, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced_gen_age <- -2 * glance(reduced_gen_age_model)$logLik), "\n")
cat("D-full:", (deviance_gen_age <- -2 * glance(gen_age_model)$logLik), "\n")
cat("G-stat:", (G_gen_age <- deviance_reduced_gen_age - deviance_gen_age), "\n")
cat("p-value:", pchisq(G_gen_age, df = 1, lower.tail = FALSE), "\n")

tidy(gen_age_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
# age / relation interaction model
reduced_rel_age_model <- glm(highProb ~ relation + age, 
              data = autism_ds, family = "binomial")
rel_age_model <- glm(highProb ~ relation*age, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced_rel_age <- -2 * glance(reduced_rel_age_model)$logLik), "\n")
cat("D-full:", (deviance_rel_age <- -2 * glance(rel_age_model)$logLik), "\n")
cat("G-stat:", (G_rel_age <- deviance_reduced_rel_age - deviance_rel_age), "\n")
cat("p-value:", pchisq(G_rel_age, df = 4, lower.tail = FALSE), "\n")

tidy(rel_age_model) |>
  kable(digits = 3)
```

```{r, include = FALSE}
# age / ethnicity interaction model
reduced_eth_age_model <- glm(highProb ~ ethnicity + age, 
              data = autism_ds, family = "binomial")
eth_age_model <- glm(highProb ~ ethnicity*age, 
              data = autism_ds, family = "binomial")

cat("D-reduced:", (deviance_reduced_eth_age <- -2 * glance(reduced_eth_age_model)$logLik), "\n")
cat("D-full:", (deviance_eth_age <- -2 * glance(eth_age_model)$logLik), "\n")
cat("G-stat:", (G_eth_age <- deviance_reduced_eth_age - deviance_eth_age), "\n")
cat("p-value:", pchisq(G_eth_age, df = 9, lower.tail = FALSE), "\n")

tidy(rel_age_model) |>
  kable(digits = 3)
```

```{r, message=FALSE, echo =FALSE, tab.cap="Non-obvious predictors drop-in-deviance test results" }
header <- c("Deviance", "G statistic (respect to null)", "p-value")
Null <- c(round(deviance_reduced, 3), "NA", "NA")

Ethnicity <- c(round(deviance_eth, 3), round(G_eth,3), round(pchisq(G_eth, df = 9, lower.tail = FALSE),5))
Relation <- c(round(deviance_rel,3), round(G_rel,3), round(pchisq(G_rel, df = 4, lower.tail = FALSE),3))
Age <- c(round(deviance_age,3), round(G_age,3), round(pchisq(G_age, df = 1, lower.tail = FALSE),3))
Gender <- c(round(deviance_gender,3), round(G_gender,3), round(pchisq(G_gender, df = 1, lower.tail = FALSE),3))
Jaundice <- c(round(deviance_j,3), round(G_j,3),  round(pchisq(G_j, df = 1, lower.tail = FALSE),3))
GenderRelation <- c(round(deviance_rel_gen,3), round(G_rel_gen,3), round(pchisq(G_rel_gen, df = 4, lower.tail = FALSE),3))
GenderEthnicity <- c(round(deviance_gen_eth,3), round(G_gen_eth,3), round(pchisq(G_gen_eth, df = 9, lower.tail = FALSE),3))
GenderAge <- c(round(deviance_gen_age,3), round(G_gen_age,3), round(pchisq(G_gen_age, df = 1, lower.tail = FALSE),3))
RelationAge <- c(round(deviance_rel_age,3), round(G_rel_age,3), round(pchisq(G_rel_age, df = 4, lower.tail = FALSE),3))
EthnicityAge <- c(round(deviance_eth_age,3), round(G_eth_age,3), round(pchisq(G_eth_age, df = 9, lower.tail = FALSE),3))

non_obvious_pred <- rbind(Null, Ethnicity, Relation, Age, Gender, Jaundice, GenderRelation, GenderEthnicity, GenderAge, RelationAge, EthnicityAge)
colnames(non_obvious_pred) <- header

kable(non_obvious_pred)
```

The results show that the demographics that may prove statistically significant for our future model are ethnicity, gender, age, and, quite surprisingly, neonatal jaundice, when compared to a null model, as the p-values are either below 0.05. Additionally, we acknowledge potential interactions between relationship to the subject and age – but as relationship to the test subject on its own appears largely insignificant as a predictor, we choose to neglect this interaction effect in our modeling to minimize complexity. We retain the potentially statistically significant predictors for our final model.

We now check our model conditions for these tests. We note that in using our statistically significant predictors later, they are all categorical and thus, do not need to assess linearity between log-odds and our predictors for the logistic regression model. We also note that presumably all of the observations of this test are independent due to no apparent spatial or temporal correlations. However, the model condition at risk is randomness, as our population is primarily those who already suspect autism. This does limit the generalization of our model to the overall population, especially as taking the screening test is voluntary, which leads to a clear response bias. However, pertaining to the population of individuals seeking screening tests, we will assume randomness within this group, and again use this primarily as an investigation of the nature of this questionnaire and associations between demographics and scores. We note an additional limitation that certain subgroups (e.g., the Pasifika ethnic group) possess small sample sizes with less than 30 observations. We further investigate the correlation between answers to questions below, as a means of assessing if the test has any pitfalls regarding multicollinearity:

```{r, echo=FALSE, message = FALSE, fig.cap = "Correlation between AQ10 questions", fig.height=2.75, fig.width=10.5}
q1_to_10 <- autism_ds |>
  select(small_sounds, difficult_to_understand_char,
         ease_to_read_between_lines,
         focus_on_whole_picture,
         i_can_tell_if_someone_bored,
         i_can_multi_task,
         i_can_tell_feelings_from_faces,
         i_can_go_back_to_work_when_interrupted,
         i_like_to_collect_info_on_categories,
         i_find_it_hard_to_figure_out_others_intentions)

cor_matrix <- cor(q1_to_10, method = "pearson", use = "complete.obs")

short_names <- c(
  "Q1", "Q2", "Q3", "Q4", "Q5",
  "Q6", "Q7", "Q8", "Q9", "Q10"
)

colnames(cor_matrix) <- short_names
rownames(cor_matrix) <- short_names

corrplot(cor_matrix,
         method = "color",
         type = "upper",
         tl.col = "black",
         tl.cex = 1,
         addCoef.col = "black",
         number.cex = 0.7,
         diag = FALSE)
```

Unexpectedly, only a few questions have moderate correlations with one another when typically we would expect many behaviors to be grouped together and more correlated (e.g., social behaviors). The highest correlation is between questions 6 and 9, which are the questions about multitasking and liking to collect information, respectively – a rather surprising pairing. Accordingly, principal component analysis was used to determine the question clusters that explain the highest variance to gain further understanding of the nature of the variety of questions in the screening test (Szczęsna, 2022; finnstats, 2021).

```{r, include=FALSE}
pca <- prcomp(autism_ds |>
     rename(
        `Q1` = small_sounds,
        `Q2` = difficult_to_understand_char,
        `Q3` = ease_to_read_between_lines,
        `Q4` = focus_on_whole_picture,
        `Q5` = i_can_tell_if_someone_bored,
        `Q6` = i_can_multi_task,
        `Q7` = i_can_tell_feelings_from_faces,
        `Q8` = i_can_go_back_to_work_when_interrupted,
        `Q9` = i_like_to_collect_info_on_categories,
        `Q10` = i_find_it_hard_to_figure_out_others_intentions
    ) |> select(Q1:Q10), center = TRUE, scale. = TRUE)
summary(pca)
# Loadings reshaped
loadings_df <- as.data.frame(pca$rotation[, 1:10]) |>
  rownames_to_column("question") |>
  pivot_longer(cols = -question, names_to = "PC", values_to = "loading")

# Keep question and PC order fixed
loadings_df$question <- factor(loadings_df$question, levels = paste0("Q", 1:10))
loadings_df$PC <- factor(loadings_df$PC, levels = paste0("PC", 1:10))
```

```{r, echo=FALSE, fig.cap = "Principal component analysis Q1-10 as a means of choosing questions that best explain the variance in the response", fig.height=5, fig.width=10.5}
# Plot
ggplot(loadings_df, aes(x = question, y = abs(loading), fill = PC)) +
  geom_col(position = "dodge") +
  coord_flip() +
  facet_wrap(~ PC, scales = "free_y") +
  labs(title = "PCA Loadings by Question", x = "Question", y = "Loading") +
  scale_fill_discrete(guide = "none") +
  theme_minimal()
```

We can observe that Q3, Q5, and Q6 have high correlation to Q4, Q6, and Q9, respectively. Beyond these three, the questions that also observe notable loading for principal components (i.e. the parameters that explain the most variance) are Q10, Q8, Q4, Q2, and Q1 (i.e finding it hard to figure out others intentions, ease of going back to work when interrupted, focus on whole picture, difficulty to understand characters in stories, and picking up on small sounds). In general, it seems that some questions form categories that are highly correlated to explain the different subsets of behaviors in autism. However, since the answer to each question might directly be added to the final result if the answer is TRUE, we decide to focus on examining the predictive power of the demographic data on the likelihood of autism.

**ii. Fitting the Model**

To identify correlations between demographic data and the odds of a high test score, two models will be fitted and compared by a drop-in-deviance test: (a) a null model fitted only to an intercept, and (b) an alternative model that accounts for our chosen demographic predictors. $$\text{Null:} \; \log(\frac{\hat\pi}{1-\hat\pi})=\beta_0$$ $$\text{Alternative:} \; \log(\frac{\hat\pi}{1-\hat\pi})=\beta_0 + \beta_{ethnicity}X_{ethnicity}+\beta_{gender}X_{gender}+\beta_{jaundice}X_{jaundice} + \beta_{age}X_{age}$$

And the hypotheses for the test will be the following: $$H_0: \beta_{ethnicity}=\beta_{gender}=\beta_{jaundice}=\beta_{age}=0$$ $$H_a: \text{at least one of} \; \beta_{ethnicity}, \beta_{gender}, \beta_{jaundice}, \beta_{age}\neq0 \space$$

This is to assess whether the chosen demographic predictors significantly improve model fit and our predictions of the odds of obtaining a high score on the test, and consequently, being encouraged to pursue an ASD diagnosis. We include AIC and BIC for further comparison. We note that we reasonably assume no multicollinearity between demographic information.

```{r, include = FALSE}
autism_ds$ethnicity <- relevel(factor(autism_ds$ethnicity), ref = "White-European")
null_mod_score_fit <- glm(highProb ~ 1, 
                            data = autism_ds, family = "binomial")

alt_mod_score_fit <- glm(highProb ~ 
                            ethnicity + 
                            gender +
                            age +
                            jundice,
                            data = autism_ds, family = "binomial")

alt_mod_score_fit_no_age <- glm(highProb ~ 
                            ethnicity + 
                            gender +
                            jundice,
                            data = autism_ds, family = "binomial")

dev_test <- anova(null_mod_score_fit, alt_mod_score_fit, test = "Chisq")

aic_null <- AIC(null_mod_score_fit)
bic_null <- BIC(null_mod_score_fit)
aic_alt <- AIC(alt_mod_score_fit)
bic_alt <- BIC(alt_mod_score_fit)

model_comparison <- tibble(
  Model = c("Null Model", "Alternative Model"),
  Residual_Deviance = c(null_mod_score_fit$deviance, alt_mod_score_fit$deviance),
  Df = c(null_mod_score_fit$df.residual, alt_mod_score_fit$df.residual),
  AIC = c(aic_null, aic_alt),
  BIC = c(bic_null, bic_alt)
)
drop_in_deviance <- tibble(
  Test = "Drop-in-deviance (Chi-sq)",
  G_stat = dev_test$Deviance[2],
  df = dev_test$Df[2],
  p_value = dev_test$`Pr(>Chi)`[2]
)
```

```{r, echo=FALSE, tab.cap="Alternative and null model comparison in terms of deviance, AIC, and BIC"}
kable(model_comparison, digits = 2)
```

Based on the output, we observe that the alternative model (i.e. the one with demographic information) performs better exhibiting lower deviance, AIC, but also surprisingly BIC, which more harshly penalizes its higher complexity.

```{r, echo=FALSE, tab.cap="Drop-in-deviance test result for alternative and null models"}
kable(drop_in_deviance, digits = 4)
```

The drop-in-deviance tests corroborates that these results are statistically significant; we reject the null hypothesis since the p-value is much less than 0.05. Hence, the alternative model will be further assessed as a means of understanding how demographic data impacts the odds of a positive screening test.

**III. Results**

A final model was fitted and is shown below. Note that age was discarded as a predictor because it showcased a p-value much greater than 0.05 (0.74) (see additional materials b.). Below is the model that includes all previously mentioned parameters without age.
```{r, echo=FALSE, tab.cap="Output for alternative model w/o age"}
tidy(alt_mod_score_fit_no_age, conf.int = TRUE, conf.level = 0.95) |>
  kable(digits = 3)
```

We note that gender and many ethnic groups possess p-values greater than 0.05. Among statistically significant demographic predictors, subjects who identify as Asian, Middle Eastern, or South Asian appear significantly less likely to be categorized as high probability for ASD with expected odds ratios (ORs) of approximately `r round(exp(-1.702),3)`, `r round(exp(-2.184),3)`, and `r round(exp(-2.196),3)` respectively, compared to the baseline category of White-European, holding all else constant. This leads us to wonder if these subgroups are more prone to under-diagnosis or others to over-diagnosis. The Pasifika population also has a notable odds ratio (`r round(exp(-2.138),3)`), but cannot generalize due to small sample side

In individuals with a history of neonatal jaundice, we expect the odds of a positive screening test to multiply by a factor of `r round(exp(0.639),3)` compared to those without, holding all else constant. In practice, this could suggest that individuals with neonatal jaundice should be screened for ASD at a higher rate than their counterparts, as we note it seems unlikely for these individuals to experience bias in their screening and diagnoses since the effects of neonatal jaundice are nearly imperceptible as adults. For that reason, we do not suspect over-diagnosis for this group.

```{r, echo=FALSE, message = FALSE, fig.height = 4.5, fig.width = 10.5}
pred_prob <- predict.glm(alt_mod_score_fit_no_age, type = "response")

# Augment model with prediction and correct factor levels
alt_mod_score_fit_aug <- augment(alt_mod_score_fit_no_age) |>
  mutate(
    highProb = factor(highProb, levels = c(0, 1))  # 0 = non-event, 1 = event
  ) |>
  bind_cols(pred_prob = pred_prob)

# Calculate ROC data
roc_curve <- alt_mod_score_fit_aug |>
  roc_curve(highProb, pred_prob, event_level = "second")

# Calculate AUC
auc_val <- alt_mod_score_fit_aug |>
  roc_auc(highProb, pred_prob, event_level = "second") |>
  pull(.estimate)

# Plot ROC curve and annotate AUC
autoplot(roc_curve) +
  ggtitle("ROC Curve with AUC") +
  annotate("text", x = 0.65, y = 0.15, label = paste("AUC =", round(auc_val, 3)), size = 5)
```

The area under the curve is 0.739, which means that the model, although not a terrible fit, is likely insufficient to explain the variation in the odds of a high score on its own. However, as a model fitted entirely to demographic data that we would expect to be independent of one's screening result, this is a notable result.

**IV. Discussion + Conclusion**

Our model predicts the likelihood of a positive ASD screening demographica results, based on a test examining various behaviors and attitudes. Although the AUC value is modest (0.739), the model's classification performance is notable given the predictors which are not derived from the test. Nonetheless, the non-randomness of the sample and small subgroup sizes limit the conclusions. These findings, however, highlight the need for further research into the relationship between ethnicity, neonatal jaundice and ASD diagnosis. The notable higher odds of a positive test among White, Black, and Hispanic individuals suggest potential for over-diagnosis and test bias. Broader comparisons and analysis on the bias of these test could provide stronger frameworks for understanding ASD diagnostic pattern in current healthcare and psychology. 

\newpage

**V. References**

-   Aishworiya, R., Kim, V., MA, Stewart, S., Hagerman, R., & Feldman, H. M. (2023). Meta-analysis of the Modified Checklist for Autism in Toddlers, Revised/Follow-up for Screening. *PEDIATRICS*, *151*(6). https://doi.org/10.1542/peds.2022-059393

-   Curnow, E., Utley, I., Rutherford, M., Johnston, L., & Maciver, D. (2023). Diagnostic assessment of autism in adults – current considerations in neurodevelopmentally informed professional learning with reference to ADOS-2. *Frontiers in Psychiatry*, *14*. https://doi.org/10.3389/fpsyt.2023.1258204

-   Faizunnabi, F. (2024). Autism Screening. [https://www.kaggle.com/datasets/faizunnabi/autism-screening](#0)

-   finnstats. (2021, May 14). Principal component analysis (PCA) in R. https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/

-   Hirota, T., & King, B. H. (2023). Autism spectrum Disorder. *JAMA*, *329*(2), 157. https://doi.org/10.1001/jama.2022.23661

-   Marin, Z. (2021, April 26). GLM fit: Algorithm did not converge – How to fix it. Statology. https://www.statology.org/glm-fit-algorithm-did-not-converge/

-   Szczęsna, K. (2022). PCA in R. RPubs. https://rpubs.com/KarolinaSzczesna/862710

-   Thabtah, F. (2017). ASDTests. A mobile app for ASD screening. [www.asdtests.co](http://www.asdtests.com/)m

\newpage

**VI. Additional Materials**

**a. Figure 5: Details**

In Figure 5, the distribution of Y/N responses for Q1-10 is illustrated. Here are the details of the 10 behavioral questions (also shown in the data dictionary).

Q1, noticing small sounds;

Q2, finding it difficult to work out character intentions;

Q3, finding it easy to read between lines;

Q4, big picture-oriented;

Q5, can tell if someone listening to me is bored;

Q6, can multitask;

Q7, can tell feelings from faces;

Q8, can go back to work when interrupted;

Q9, enjoy collecting info on categories;

Q10, find it difficult to work out people's intentions.

One thing to note is that while we renamed the ten variables to more descriptive names in our dataset for clarity, we decided to use the Q1–Q10 labels in the visualization for simplicity and cleaner presentation.

**b. Alternative Final Model With Age**
```{r, echo=FALSE}
tidy(alt_mod_score_fit, conf.int = TRUE, conf.level = 0.95) |>
  kable(digits = 3)
```
A model that took into account age was previously fitted as it proved to be significant in the drop-in-deviance test with respect to the intercept. However, further inspection idicated it was not a significant predictor, as it had a p-value of 0.724. Subsequently, it was emoved as a predictor
